{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f32545b7-8f4c-43d4-91a1-a4a8fd8dbdcb",
   "metadata": {},
   "source": [
    "# üì¶ spaCy Matcher\n",
    "## üß† What is Phrase Matching?\n",
    "- Phrase matching is the process of identifying predefined phrases (multi-word expressions) in text.\n",
    "- In spaCy, this is efficiently handled using the _**<code>Matcher</code>**_ class, which can match patterns based on tokens, and the _**<code>PhraseMatcher</code>**_ class, which is optimized specifically for matching sequences of tokens (phrases).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b05de5a-667b-47c8-8a2b-8416bb7723a5",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 1. Setup: Install & Load spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f9a4c6f-48e4-4e45-8bf9-1fc98ac7098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a matcher object\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b3505-1ad3-42b9-ad5a-3e488b8700cf",
   "metadata": {},
   "source": [
    "## üìö 2. Basic Matcher Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d584d266-1727-45b0-ad30-14348070aa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: Data Science\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"LOWER\": \"data\"},\n",
    "    {\"LOWER\": \"science\"}\n",
    "]\n",
    "\n",
    "matcher.add(\"DATA_SCIENCE\", [pattern])\n",
    "doc = nlp(\"I love learning Data Science and Data Engineering.\")\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(f\"Matched: {span.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54633aa1-01ed-4c2d-962b-a721b0939894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 8, 9), (8656102463236116519, 11, 14)]\n",
      "-----------------------------------------------------------------------------------\n",
      "8656102463236116519 SolarPower 1 3 Solar Power\n",
      "8656102463236116519 SolarPower 8 9 solarpower\n",
      "8656102463236116519 SolarPower 11 14 Solar-power\n"
     ]
    }
   ],
   "source": [
    "# SolarPower\n",
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "\n",
    "# Solar-power\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True},{'LOWER':'power'}]\n",
    "\n",
    "# Solar power\n",
    "pattern3 = [{'LOWER':'solar'},{'LOWER':'power'}]\n",
    "\n",
    "#help(matcher.add)\n",
    "matcher.add('SolarPower', [pattern1, pattern2, pattern3])\n",
    "\n",
    "doc = nlp(\"The Solar Power industry continues to grow a solarpower increases. Solar-power is amazing.\")\n",
    "\n",
    "found_matches = matcher(doc)\n",
    "print(found_matches)\n",
    "print(\"-----------------------------------------------------------------------------------\")\n",
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] # get string representation\n",
    "    span = doc[start:end]    # get the matched span\n",
    "    print(match_id,  string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2d1412-9055-40c2-9c40-9ce23c76e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(matcher.add)\n",
    "\n",
    "matcher.remove('SolarPower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9195357a-87c5-4976-bbbd-2ea9dc8064e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 0 3 Solar--power\n",
      "8656102463236116519 SolarPower 4 5 solarpower\n"
     ]
    }
   ],
   "source": [
    "# solarpower SolarPower\n",
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "\n",
    "# solar.power or solar-*&power, etc\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True,'OP':'*'},{'LOWER':'power'}]\n",
    "\n",
    "matcher.add('SolarPower',[pattern1, pattern2])\n",
    "\n",
    "doc2 = nlp('Solar--power is solarpower yay!')\n",
    "found_matches = matcher(doc2)\n",
    "for match_id, start, end in found_matches:\n",
    "    str_id = nlp.vocab.strings[match_id]\n",
    "    span = doc2[start:end]\n",
    "    print(match_id, str_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cdfeba-f5e0-44b0-9cb5-719c4135fa18",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è 3. Using Token Attributes\n",
    "- Let‚Äôs go through several key token attributes used in patterns:\n",
    "\n",
    "| Attribute  | Description      | Example                                   |\n",
    "| ---------- | ---------------- | ----------------------------------------- |\n",
    "| `TEXT`     | Exact text       | `\"TEXT\": \"machine\"`                       |\n",
    "| `LOWER`    | Lowercased text  | `\"LOWER\": \"machine\"`                      |\n",
    "| `LEMMA`    | Base form        | `\"LEMMA\": \"be\"` matches \"is\", \"was\", etc. |\n",
    "| `POS`      | Part-of-speech   | `\"POS\": \"NOUN\"`                           |\n",
    "| `TAG`      | Fine-grained POS | `\"TAG\": \"VBD\"` for past tense             |\n",
    "| `IS_ALPHA` | Is it a word?    | `\"IS_ALPHA\": True`                        |\n",
    "| `IS_DIGIT` | Is it a digit?   | `\"IS_DIGIT\": True`                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc03bdc-68cb-45d7-bff5-da0637dd02f0",
   "metadata": {},
   "source": [
    "## üß† 4. Advanced Example: Match Adjective followed by Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e92786c-173d-44d6-9260-12ec1b442bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: great ideas\n",
      "Match: amazing energy\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"POS\": \"ADJ\"},  # Adjective\n",
    "    {\"POS\": \"NOUN\"}  # Noun\n",
    "]\n",
    "\n",
    "matcher.add(\"ADJ_NOUN\", [pattern])\n",
    "doc = nlp(\"She has great ideas and amazing energy.\")\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match:\", doc[start:end].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a355c-1ccf-4f77-9576-6931dc62c5fa",
   "metadata": {},
   "source": [
    "## üîÅ 5. Using Wildcards and Quantifiers\n",
    "### Match \"deep learning\" or \"deep neural network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff6ce276-eb4f-4ab1-b33f-a64c85d09b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: Deep neural learning\n",
      "Match: neural learning\n",
      "Match: deep learning\n",
      "Match: Deep neural learning is different from deep learning\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"LOWER\": \"deep\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"+\"},  # One or more words\n",
    "    {\"LOWER\": \"learning\"}\n",
    "]\n",
    "\n",
    "matcher.add(\"DEEP_PATTERN\", [pattern])\n",
    "doc = nlp(\"Deep neural learning is different from deep learning.\")\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match:\", doc[start:end].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a18c1-e79c-414a-b646-607ff3ffd446",
   "metadata": {},
   "source": [
    "## Operators OP for Repetition & Optionality\n",
    "\n",
    "| OP Symbol | Meaning           |\n",
    "| --------- | ----------------- |\n",
    "| `\"?\"`     | optional (0 or 1) |\n",
    "| `\"*\"`     | 0 or more times   |\n",
    "| `\"+\"`     | 1 or more times   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11303ee8-e5f4-4396-91f7-d5e99eb38c01",
   "metadata": {},
   "source": [
    "## üîÑ 6. Match Numbers Followed by Nouns (e.g., \"5 apples\", \"100 dollars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a72d8135-083e-458e-9a9c-7d1be77449a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: 5 apples\n",
      "Match: 100 dollars\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"LIKE_NUM\": True},\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "\n",
    "matcher.add(\"NUM_NOUN\", [pattern])\n",
    "doc = nlp(\"He bought 5 apples and 100 dollars worth of items.\")\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match:\", doc[start:end].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1bffd2-ca6a-4fd7-aee8-9ccbbbb10a5c",
   "metadata": {},
   "source": [
    "## üéØ 7. Named Entity + Custom Rule Matching (e.g., Person + Verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eb3934d-1dd0-4f51-b7ab-756aa250aaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: Musk founded\n",
      "Match: Elon Musk founded\n",
      "Match: Gate leads\n",
      "Match: Bill Gate leads\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"ENT_TYPE\": \"PERSON\"},\n",
    "    {\"POS\": \"VERB\"}\n",
    "]\n",
    "\n",
    "matcher.add(\"PERSON_VERB\", [pattern])\n",
    "doc = nlp(\"Elon Musk founded SpaceX. Bill Gate leads Microsoft.\")\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match:\", doc[start:end].text)\n",
    "    print(\"Match:\", doc[start-1:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4d1847-6129-459e-a355-49fcf26215fc",
   "metadata": {},
   "source": [
    "## üîÑ Step 8: Multiple Patterns for a Single Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3047749-9160-47ed-b5b1-c1d8b2785786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: Deep learning\n",
      "Match: natural language processing\n",
      "Match: machine learning\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"TECH_TERMS\", [\n",
    "    [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}],\n",
    "    [{\"LOWER\": \"deep\"}, {\"LOWER\": \"learning\"}],\n",
    "    [{\"LOWER\": \"natural\"}, {\"LOWER\": \"language\"}, {\"LOWER\": \"processing\"}]\n",
    "])\n",
    "\n",
    "doc = nlp(\"Deep learning and natural language processing are branches of machine learning.\")\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match:\", doc[start:end].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430950c6-0e63-42e5-a824-52e8faa46c6c",
   "metadata": {},
   "source": [
    "## üßº Step 9: Removing or Listing Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07a81606-d166-4d90-ad7d-0904c6090601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added pattern names: ['DATA_SCIENCE', 'MACHINE_LEARNING']\n"
     ]
    }
   ],
   "source": [
    "# matcher.remove(\"TECH_TERMS\")\n",
    "\n",
    "# How to List Added Match Patterns Properly\n",
    "from spacy.matcher import Matcher\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add a few example patterns\n",
    "matcher.add(\"DATA_SCIENCE\", [[{\"LOWER\": \"data\"}, {\"LOWER\": \"science\"}]])\n",
    "matcher.add(\"MACHINE_LEARNING\", [[{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}]])\n",
    "\n",
    "# List all rule names added to the matcher\n",
    "pattern_names = list(matcher._patterns.keys())\n",
    "pattern_names = [nlp.vocab.strings[pid] for pid in pattern_names]\n",
    "\n",
    "print(\"Added pattern names:\", pattern_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b4cb2-3ea8-49d6-a075-052cb04ef3be",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary: When to Use Matcher\n",
    "\n",
    "| Use Case                          | Use `Matcher`?               |\n",
    "| --------------------------------- | ---------------------------- |\n",
    "| Fixed phrases                     | ‚ùå Use `PhraseMatcher`        |\n",
    "| POS-based patterns                | ‚úÖ Yes                        |\n",
    "| Patterns involving entity types   | ‚úÖ Yes                        |\n",
    "| Repetitions, optional tokens      | ‚úÖ Yes                        |\n",
    "| Sentence/structure-level patterns | Consider `DependencyMatcher` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0b72fe-5a61-4c36-a334-dc66c6518888",
   "metadata": {},
   "source": [
    "# üß† Phrase Matching?\n",
    "\n",
    "## üì¶ Step 1: Install spaCy and Load Language Model\n",
    "```\n",
    "pip install spacy\n",
    "python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c4de0c-5c81-40e9-9b75-52eb11ae3276",
   "metadata": {},
   "source": [
    "# üìò Step 2: Load Language Model and Import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca1ee086-0f30-4cd7-a820-dea42df68736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create PhraseMatcher object\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c448f48-15fa-4c24-bb86-8db06d9127b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2351661100535932681 EcoMatcher 41 46 supply-side economics,\n",
      "2351661100535932681 EcoMatcher 49 53 trickle-down economics\n",
      "2351661100535932681 EcoMatcher 54 56 voodoo economics\n",
      "2351661100535932681 EcoMatcher 61 65 free-market economics\n",
      "2351661100535932681 EcoMatcher 2987 2991 trickle-down economics\n"
     ]
    }
   ],
   "source": [
    "# Read a sample document\n",
    "with open('./reaganomics.txt') as f:\n",
    "    doc3 = nlp(f.read())\n",
    "    \n",
    "# Step 3: Define the List of Phrases\n",
    "phrases_list = ['voodoo economics','supply-side economics,','trickle-down economics','free-market economics']\n",
    "\n",
    "# Step 4: Create Phrase Patterns\n",
    "phrase_pattern = [nlp(text) for text in phrases_list]\n",
    "\n",
    "# Step 5: Add Patterns\n",
    "matcher.add('EcoMatcher',phrase_pattern)\n",
    "\n",
    "# Step 6: Apply the matcher to the doc\n",
    "found_matches = matcher(doc3)\n",
    "\n",
    "# Step 7: Display the results\n",
    "for match_id, start, end in found_matches:\n",
    "    str_id = nlp.vocab.strings[match_id]\n",
    "    span = doc3[start:end]\n",
    "    print(match_id, str_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8183b-ce21-4337-82f1-f62227b80aeb",
   "metadata": {},
   "source": [
    "## üîÅ Bonus: Matching Case Insensitively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af481b90-b7b2-4236-87a0-34d32cafeeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")  # Make it case-insensitive\n",
    "#matcher.add(\"EcoMatcher\", patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e87bf-ef0e-4972-b010-e0cb086ee616",
   "metadata": {},
   "source": [
    "## üß† Understanding How It Works\n",
    "- <code>PhraseMatcher</code> matches exact sequences of tokens.\n",
    "- It is faster and more efficient than <code>Matcher</code> when you have predefined phrases.\n",
    "- The <code>add()</code> function takes:\n",
    "    - <code>label</code>: category name (used in <code>match_id</code>)\n",
    "    - <code>patterns</code>: list of Doc objects\n",
    "- The output <code>matches</code> is a list of tuples: (<code>match_id, start_index, end_index</code>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bb8771-2d72-424b-bd81-f32dd86fc807",
   "metadata": {},
   "source": [
    "# üîÑ PhraseMatcher vs Matcher\n",
    "\n",
    "| Feature     | PhraseMatcher                | Matcher                              |\n",
    "| ----------- | ---------------------------- | ------------------------------------ |\n",
    "| Purpose     | Match exact phrases          | Match patterns with token attributes |\n",
    "| Speed       | Faster                       | Slightly slower                      |\n",
    "| Flexibility | Less flexible                | Very flexible (POS, DEP, etc.)       |\n",
    "| Use Case    | Lookup dictionaries, phrases | Complex rule-based matching          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aebad00-46fa-4a1a-94d8-63283355bca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp-env]",
   "language": "python",
   "name": "conda-env-nlp-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
